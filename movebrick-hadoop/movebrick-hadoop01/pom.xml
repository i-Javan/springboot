<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>movebrick-hadoop</artifactId>
        <groupId>com.github.i-javan</groupId>
        <version>1.0</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>
    <url>https://github.com/LockieZou/hadoop</url>

    <artifactId>movebrick-hadoop01</artifactId>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <java.version>1.8</java.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
            <!--排除这个slf4j-log4j12-->
            <exclusions>
                <exclusion>
                    <groupId>org.slf4j</groupId>
                    <artifactId>slf4j-log4j12</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>2.8.5</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-hdfs</artifactId>
            <version>2.8.5</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>2.8.5</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-mapreduce-client-core</artifactId>
            <version>2.8.5</version>
        </dependency>
        <dependency>
            <groupId>cn.bestwu</groupId>
            <artifactId>ik-analyzers</artifactId>
            <version>5.1.0</version>
        </dependency>
    </dependencies>

<!--    &lt;!&ndash; 使用阿里云镜像 &ndash;&gt;-->
<!--    <repositories>-->
<!--        <repository>-->
<!--            <id>central</id>-->
<!--            <name>aliyun maven</name>-->
<!--            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>-->
<!--            <layout>default</layout>-->
<!--            &lt;!&ndash; 是否开启发布版构件下载 &ndash;&gt;-->
<!--            <releases>-->
<!--                <enabled>true</enabled>-->
<!--            </releases>-->
<!--            &lt;!&ndash; 是否开启快照版构件下载 &ndash;&gt;-->
<!--            <snapshots>-->
<!--                <enabled>false</enabled>-->
<!--            </snapshots>-->
<!--        </repository>-->
<!--    </repositories>-->
</project>

<!--hadoop-mapreduce-example：-->
<!--        aggregatewordcount 计算输入文件中文字个数的基于聚合的MapReduce程序；-->
<!--        aggregatewordlist  生成输入文件中文字个数的统计图的基于聚合的MapReduce程序；-->
<!--        grep 计算输入文件中匹配正则表达式的文字个数的MapReduce程序；-->
<!--        join 合并排序的平均分割的数据库的作业；-->
<!--        pentomino 解决五格拼板问题的分块分层的MapReduce程序；-->
<!--        pi 使用蒙地卡罗法计算pi的MapReduce程序；-->
<!--        Randomtextwriter 在一个节点上写10G随机文本的MapReduce程序；-->
<!--        randomwriter 在每个节点上写10G随机数据的MapReduce程序；-->
<!--        sleep 在每个Map和Reduce作业中休憩的程序；-->
<!--        sort 排序随机写入器生成的数据的MapReduce程序；-->
<!--        sudoku 一个九宫格游戏的解决方案；-->
<!--        wordcount 在输入文件中统计文字个的统计器。-->

<!--Hadoop:-->
<!--    离线处理：MapReduce(Distributed Computation): MapReduce是一种并行编程模型，用于编程普通硬件的设计，谷歌对大量数据的高效处理（-->
<!--        多TB数据集）的分布式应用在大型集群（数千个节点）以及可靠的容错方式。MapReduce程序可在Apache的开源Hadoop上运行。-->
<!--    文件系统：Hadoop Hdfs:Hadoop分布式系统是基于谷歌文件系统（GFS），并提供了一个设计在普通硬件上运行的分布式系统。它与现有的分布式-->
<!--        文件系统有许多相似之处。来自其他分布式文件系统的差别是显著。他高度容错并设计成部署在低成本的硬件。提供了高吞吐量的-->
<!--        应用数据访问，并且适用于具有大数据集的应用程序。-->
<!--    实用工具：Hadoop Common Utilities：这是java库和其他Hadoop组件所需的实用工具。-->
<!--    资源管理：Hadoop YARN Framework:作业调度和集群资源管理的框架。-->

<!--Hadoop如何工作？-->
<!--    建立重配置，处理大规模处理服务器这是相当昂贵的，但是作为替代，可以联系许多普通电脑采用单CPU在一起，作为一个单一功能的-->
<!--    分布式系统，实际上，集群机可以平行读取数据集，并提供一个高得多的吞吐量。此外，这样便宜不到一个高端服务器价格。因此使用-->
<!--    Hadoop跨越集群和低成本的机器上运行是一个不错不选择。-->

<!--Hadoop运行整个计算机集群代码。这个过程包括以下核心任务由 Hadoop 执行：-->
<!--        数据最初分为目录和文件。文件分为128M和64M（128M最好）统一大小块。-->
<!--        然后这些文件被分布在不同的群集节点，以便进一步处理。-->
<!--        HDFS，本地文件系统的顶端﹑监管处理。-->
<!--        块复制处理硬件故障。-->
<!--        检查代码已成功执行。-->
<!--        执行发生映射之间，减少阶段的排序。-->
<!--        发送排序的数据到某一计算机。-->
<!--        为每个作业编写的调试日志。-->




